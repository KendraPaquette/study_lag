{
  "hash": "ef0c13175ec7d531f655df2981ea134f",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Model evaluation\"\nauthor: \"Kendra Wyant\"\ndate: \"2024-11-04\"\noutput: \n  html_document:\n    toc: true \n    toc_depth: 4\nformat:\n  html:\n    embed-resources: true\neditor_options: \n  chunk_output_type: console\n---\n\n\n\n### Set Up Environment\n\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nsuppressPackageStartupMessages(library(tidyverse))\nsuppressPackageStartupMessages(source(\"https://github.com/jjcurtin/lab_support/blob/main/format_path.R?raw=true\"))\nsuppressPackageStartupMessages(library(tidyposterior))\n\npath_models_lag <- format_path(str_c(\"studydata/risk/models/lag\"))\npath_shared <- format_path(\"studydata/risk/data_processed/shared\")\npath_processed <- format_path(\"studydata/risk/data_processed/lag\")\n\noptions(knitr.kable.NA = '')\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\ntest_metrics_0 <- read_csv(here::here(path_models_lag, \n                                        \"test_metrics_1week_0_v1_nested.csv\"), \n                              col_types = cols()) |> \n  filter(.metric == \"roc_auc\") |> \n  select(outer_split_num, \"lag0\" = .estimate)\n\ntest_metrics_24 <- read_csv(here::here(path_models_lag, \n                                       \"test_metrics_1week_24_v1_nested.csv\"),\n                             col_types = cols()) |> \n  filter(.metric == \"roc_auc\") |> \n  select(outer_split_num, \"lag24\" = .estimate)\n\ntest_metrics_72 <- read_csv(here::here(path_models_lag, \n                                        \"test_metrics_1week_72_v1_nested.csv\"),\n                              col_types = cols()) |> \n  filter(.metric == \"roc_auc\") |> \n  select(outer_split_num, \"lag72\" = .estimate)\n\ntest_metrics_168 <- read_csv(here::here(path_models_lag, \n                                        \"test_metrics_1week_168_v1_nested.csv\"), \n                              col_types = cols()) |> \n  filter(.metric == \"roc_auc\") |> \n  select(outer_split_num, \"lag168\" = .estimate)\n\ntest_metrics_336 <- read_csv(here::here(path_models_lag, \n                                       \"test_metrics_1week_336_v1_nested.csv\"),\n                             col_types = cols()) |> \n  filter(.metric == \"roc_auc\") |> \n  select(outer_split_num, \"lag336\" = .estimate)\n\ntest_metrics_all <- test_metrics_0 |> \n  left_join(test_metrics_24, by = c(\"outer_split_num\")) |> \n  left_join(test_metrics_72, by = c(\"outer_split_num\")) |>\n  left_join(test_metrics_168, by = c(\"outer_split_num\")) |>\n  left_join(test_metrics_336, by = c(\"outer_split_num\")) |> \n  mutate(fold_num = rep(1:10, 3),\n         repeat_num = c(rep(1, 10), rep(2, 10), rep(3, 10))) |> \n  select(-outer_split_num) |> \n  glimpse()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 30\nColumns: 7\n$ lag0       <dbl> 0.8751586, 0.8951046, 0.8915280, 0.9109163, 0.9107734, 0.94…\n$ lag24      <dbl> 0.8570908, 0.8958414, 0.8922776, 0.9160835, 0.8868194, 0.93…\n$ lag72      <dbl> 0.8491782, 0.8787232, 0.8719031, 0.9072133, 0.8739759, 0.92…\n$ lag168     <dbl> 0.8504410, 0.8865674, 0.8222166, 0.9222604, 0.8391237, 0.91…\n$ lag336     <dbl> 0.8168572, 0.8723169, 0.7801488, 0.8706801, 0.8447883, 0.89…\n$ fold_num   <int> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1…\n$ repeat_num <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,…\n```\n\n\n:::\n:::\n\n\n\n\n#### Model evaluation\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n#| output: false\n\n# Repeated CV (id = repeat, id2 = fold within repeat)\n# with a common variance:  statistic ~ model + (model | id2/id)\nset.seed(101)\npp <- test_metrics_all |> \n  rename(id = fold_num,\n         id2 = repeat_num) |> \n  perf_mod(formula = statistic ~ model + (1 | id2/id),\n         transform = tidyposterior::logit_trans,  # for skewed & bounded AUC\n         iter = 3000, chains = 4, adapt_delta = .99, # increased iteration from 2000 to fix divergence issues\n         family = gaussian, \n)  \n```\n\n::: {.cell-output .cell-output-stdout .hidden}\n\n```\n\nSAMPLING FOR MODEL 'continuous' NOW (CHAIN 1).\nChain 1: \nChain 1: Gradient evaluation took 7.4e-05 seconds\nChain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.74 seconds.\nChain 1: Adjust your expectations accordingly!\nChain 1: \nChain 1: \nChain 1: Iteration:    1 / 3000 [  0%]  (Warmup)\nChain 1: Iteration:  300 / 3000 [ 10%]  (Warmup)\nChain 1: Iteration:  600 / 3000 [ 20%]  (Warmup)\nChain 1: Iteration:  900 / 3000 [ 30%]  (Warmup)\nChain 1: Iteration: 1200 / 3000 [ 40%]  (Warmup)\nChain 1: Iteration: 1500 / 3000 [ 50%]  (Warmup)\nChain 1: Iteration: 1501 / 3000 [ 50%]  (Sampling)\nChain 1: Iteration: 1800 / 3000 [ 60%]  (Sampling)\nChain 1: Iteration: 2100 / 3000 [ 70%]  (Sampling)\nChain 1: Iteration: 2400 / 3000 [ 80%]  (Sampling)\nChain 1: Iteration: 2700 / 3000 [ 90%]  (Sampling)\nChain 1: Iteration: 3000 / 3000 [100%]  (Sampling)\nChain 1: \nChain 1:  Elapsed Time: 4.725 seconds (Warm-up)\nChain 1:                4.422 seconds (Sampling)\nChain 1:                9.147 seconds (Total)\nChain 1: \n\nSAMPLING FOR MODEL 'continuous' NOW (CHAIN 2).\nChain 2: \nChain 2: Gradient evaluation took 3.2e-05 seconds\nChain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.32 seconds.\nChain 2: Adjust your expectations accordingly!\nChain 2: \nChain 2: \nChain 2: Iteration:    1 / 3000 [  0%]  (Warmup)\nChain 2: Iteration:  300 / 3000 [ 10%]  (Warmup)\nChain 2: Iteration:  600 / 3000 [ 20%]  (Warmup)\nChain 2: Iteration:  900 / 3000 [ 30%]  (Warmup)\nChain 2: Iteration: 1200 / 3000 [ 40%]  (Warmup)\nChain 2: Iteration: 1500 / 3000 [ 50%]  (Warmup)\nChain 2: Iteration: 1501 / 3000 [ 50%]  (Sampling)\nChain 2: Iteration: 1800 / 3000 [ 60%]  (Sampling)\nChain 2: Iteration: 2100 / 3000 [ 70%]  (Sampling)\nChain 2: Iteration: 2400 / 3000 [ 80%]  (Sampling)\nChain 2: Iteration: 2700 / 3000 [ 90%]  (Sampling)\nChain 2: Iteration: 3000 / 3000 [100%]  (Sampling)\nChain 2: \nChain 2:  Elapsed Time: 4.926 seconds (Warm-up)\nChain 2:                2.199 seconds (Sampling)\nChain 2:                7.125 seconds (Total)\nChain 2: \n\nSAMPLING FOR MODEL 'continuous' NOW (CHAIN 3).\nChain 3: \nChain 3: Gradient evaluation took 3.1e-05 seconds\nChain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.31 seconds.\nChain 3: Adjust your expectations accordingly!\nChain 3: \nChain 3: \nChain 3: Iteration:    1 / 3000 [  0%]  (Warmup)\nChain 3: Iteration:  300 / 3000 [ 10%]  (Warmup)\nChain 3: Iteration:  600 / 3000 [ 20%]  (Warmup)\nChain 3: Iteration:  900 / 3000 [ 30%]  (Warmup)\nChain 3: Iteration: 1200 / 3000 [ 40%]  (Warmup)\nChain 3: Iteration: 1500 / 3000 [ 50%]  (Warmup)\nChain 3: Iteration: 1501 / 3000 [ 50%]  (Sampling)\nChain 3: Iteration: 1800 / 3000 [ 60%]  (Sampling)\nChain 3: Iteration: 2100 / 3000 [ 70%]  (Sampling)\nChain 3: Iteration: 2400 / 3000 [ 80%]  (Sampling)\nChain 3: Iteration: 2700 / 3000 [ 90%]  (Sampling)\nChain 3: Iteration: 3000 / 3000 [100%]  (Sampling)\nChain 3: \nChain 3:  Elapsed Time: 4.751 seconds (Warm-up)\nChain 3:                4.586 seconds (Sampling)\nChain 3:                9.337 seconds (Total)\nChain 3: \n\nSAMPLING FOR MODEL 'continuous' NOW (CHAIN 4).\nChain 4: \nChain 4: Gradient evaluation took 3.2e-05 seconds\nChain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.32 seconds.\nChain 4: Adjust your expectations accordingly!\nChain 4: \nChain 4: \nChain 4: Iteration:    1 / 3000 [  0%]  (Warmup)\nChain 4: Iteration:  300 / 3000 [ 10%]  (Warmup)\nChain 4: Iteration:  600 / 3000 [ 20%]  (Warmup)\nChain 4: Iteration:  900 / 3000 [ 30%]  (Warmup)\nChain 4: Iteration: 1200 / 3000 [ 40%]  (Warmup)\nChain 4: Iteration: 1500 / 3000 [ 50%]  (Warmup)\nChain 4: Iteration: 1501 / 3000 [ 50%]  (Sampling)\nChain 4: Iteration: 1800 / 3000 [ 60%]  (Sampling)\nChain 4: Iteration: 2100 / 3000 [ 70%]  (Sampling)\nChain 4: Iteration: 2400 / 3000 [ 80%]  (Sampling)\nChain 4: Iteration: 2700 / 3000 [ 90%]  (Sampling)\nChain 4: Iteration: 3000 / 3000 [100%]  (Sampling)\nChain 4: \nChain 4:  Elapsed Time: 4.103 seconds (Warm-up)\nChain 4:                4.334 seconds (Sampling)\nChain 4:                8.437 seconds (Total)\nChain 4: \n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\npp_tidy <- pp |> \n  tidy(seed = 123) \n\nq = c(.025, .5, .975)\ntest_metrics_all_pp_perf <- pp_tidy |> \n  group_by(model) |> \n  summarize(pp_median = quantile(posterior, probs = q[2]),\n            pp_lower = quantile(posterior, probs = q[1]), \n            pp_upper = quantile(posterior, probs = q[3])) |> \n  mutate(model = factor(model, levels = c(\"lag0\", \"lag24\", \"lag72\", \"lag168\", \"lag336\"),\n                        labels = c(\"0 lag\", \"24 lag\", \"72 lag\", \"168 lag\", \"336 lag\"))) |> \n  arrange(model)\n\ntest_metrics_all_pp_perf |> \n  write_csv(here::here(path_models_lag, \"test_metrics_all_pp_perf.csv\"))\n\npp_tidy |> \n  write_csv(here::here(path_models_lag, \"pp_tidy.csv\"))\n\ntest_metrics_all_pp_perf\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 5 × 4\n  model   pp_median pp_lower pp_upper\n  <fct>       <dbl>    <dbl>    <dbl>\n1 0 lag       0.892    0.872    0.910\n2 24 lag      0.886    0.865    0.905\n3 72 lag      0.874    0.851    0.894\n4 168 lag     0.869    0.846    0.891\n5 336 lag     0.851    0.825    0.874\n```\n\n\n:::\n:::\n\n\n\n\n\nSee if brms replicates\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n# library(brms)\n# \n# data <- test_metrics_all |> \n#   rename(id = fold_num,\n#          id2 = repeat_num) |> \n#   pivot_longer(cols = starts_with(\"lag\"), \n#                names_to = \"model\", \n#                values_to = \"statistic\")\n# \n# pp_brm <-  brm(\n#   formula = statistic ~ model + (1 | id2/id), # folds nested in repeats\n#   data = data,\n#   family = gaussian(link = \"logit\"), # normal distribution w/auroc bounded between 0 and 1\n#   chains = 4,\n#   control = list(adapt_delta = 0.99), \n#   iter = 3000,\n#   seed = 101\n# )\n# \n# pp_tidy <- posterior_predict(pp_brm, type = \"response\") |>  # rows observation, columns observations\n#   as_tibble(.name_repair = \"unique\") |> \n#   pivot_longer(cols = everything(), \n#                names_to = \"draw\", \n#                values_to = \"posterior\") |>\n#   bind_cols(data$model)\n\n\n# Calculate AUC\n# roc_result <- roc(your_data$outcome, rowMeans(predictions))\n# auc_value <- auc(roc_result)\n# \n# print(auc_value)\n```\n:::\n\n\n\n\n\n\n### Model Comparisons\n\n#### Baseline Contrasts\n\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nci_baseline <- pp |>\n  contrast_models(list(\"lag0\", \"lag0\", \"lag0\", \"lag0\"), \n                  list(\"lag24\", \"lag72\", \"lag168\", \"lag336\")) |> \n  summary(size = 0) |> \n  mutate(contrast = factor(contrast, \n                           levels = c(\"lag0 vs lag24\", \"lag0 vs lag72\", \"lag0 vs lag168\", \n                                      \"lag0 vs lag336\"),\n                           labels = c(\"0 vs. 24\", \"0 vs. 72\", \n                                      \"0 vs. 168\", \"0 vs. 336\")))\n\nci_median_baseline <- pp |> \n  contrast_models(list(\"lag0\", \"lag0\", \"lag0\", \"lag0\"), \n                  list(\"lag24\", \"lag72\", \"lag168\", \"lag336\")) |>  \n  group_by(contrast) |> \n  summarize(median = quantile(difference, .5)) |> \n  mutate(contrast = factor(contrast, \n                           levels = c(\"lag0 vs. lag24\", \"lag0 vs. lag72\", \"lag0 vs. lag168\", \n                                      \"lag0 vs. lag336\"),\n                           labels = c(\"0 vs. 24\", \"0 vs. 72\", \n                                      \"0 vs. 168\", \"0 vs. 336\")))\n\n\nci_baseline <- ci_baseline |> \n  left_join(ci_median_baseline, by = c(\"contrast\")) \n\nci_baseline |> \n  write_csv(here::here(path_models_lag, \"ci_baseline.csv\"))\n\nci_baseline\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 4 × 10\n  contrast  probability    mean    lower  upper  size pract_neg pract_equiv\n  <fct>           <dbl>   <dbl>    <dbl>  <dbl> <dbl>     <dbl>       <dbl>\n1 0 vs. 168       1     0.0226  0.0160   0.0294     0        NA          NA\n2 0 vs. 24        0.956 0.00599 0.000236 0.0119     0        NA          NA\n3 0 vs. 336       1     0.0411  0.0332   0.0495     0        NA          NA\n4 0 vs. 72        1     0.0182  0.0119   0.0248     0        NA          NA\n# ℹ 2 more variables: pract_pos <dbl>, median <dbl>\n```\n\n\n:::\n:::\n\n\n\n\n#### Adjacent Contrasts\n\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nci_lag <- pp |>\n  contrast_models(list(\"lag24\", \"lag72\", \"lag168\"), \n                  list(\"lag72\", \"lag168\", \"lag336\")) |> \n  summary(size = 0) |> \n  mutate(contrast = factor(contrast, \n                           levels = c(\"lag24 vs lag72\", \"lag72 vs lag168\", \n                                      \"lag168 vs lag336\"),\n                           labels = c(\"24 vs. 72\", \"72 vs. 168\", \"168 vs. 336\")))\n\nci_median_lag <- pp |> \n  contrast_models(list(\"lag24\", \"lag72\", \"lag168\"), \n                  list(\"lag72\", \"lag168\", \"lag336\")) |>  \n  group_by(contrast) |> \n  summarize(median = quantile(difference, .5)) |> \n  mutate(contrast = factor(contrast, \n                           levels = c(\"lag24 vs. lag72\", \"lag72 vs. lag168\", \n                                      \"lag168 vs. lag336\"),\n                           labels = c(\"24 vs. 72\", \"72 vs. 168\", \"168 vs. 336\")))\n\nci_lag <- ci_lag |> \n  left_join(ci_median_lag, by = c(\"contrast\")) |> \n  arrange(contrast)\n\nci_lag |> \n  write_csv(here::here(path_models_lag, \"ci_lag.csv\"))\n\nci_lag\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 3 × 10\n  contrast    probability    mean    lower  upper  size pract_neg pract_equiv\n  <fct>             <dbl>   <dbl>    <dbl>  <dbl> <dbl>     <dbl>       <dbl>\n1 24 vs. 72         0.998 0.0122   0.00594 0.0188     0        NA          NA\n2 72 vs. 168        0.862 0.00443 -0.00221 0.0112     0        NA          NA\n3 168 vs. 336       1     0.0185   0.0113  0.0259     0        NA          NA\n# ℹ 2 more variables: pract_pos <dbl>, median <dbl>\n```\n\n\n:::\n:::\n",
    "supporting": [
      "ana_bayesian_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}