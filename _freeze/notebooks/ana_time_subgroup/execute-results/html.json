{
  "hash": "32824938dd8fedc20a79281247e0e0d1",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Group by Time Effects\"\nauthor: \"Kendra Wyant\"\ndate: \"2024-11-06\"\noutput: \n  html_document:\n    toc: true \n    toc_depth: 4\nformat:\n  html:\n    embed-resources: true\neditor_options: \n  chunk_output_type: console\n---\n\n\n\n### Set Up Environment\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n#| message: false\n#| warning: false\n\n# handle conflicts\noptions(conflicts.policy = \"depends.ok\")\ndevtools::source_url(\"https://github.com/jjcurtin/lab_support/blob/main/fun_ml.R?raw=true\")\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nℹ SHA-1 hash of file is \"77e91675366f10788c6bcb59fa1cfc9ee0c75281\"\n```\n\n\n:::\n\n```{.r .cell-code .hidden}\n#| message: false\n#| warning: false\n\ntidymodels_conflictRules()\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n#| message: false\n#| warning: false\n\nsuppressPackageStartupMessages(library(tidyverse))\nsuppressPackageStartupMessages(library(tidymodels))\nsuppressPackageStartupMessages(library(tidyposterior))\nlibrary(kableExtra, exclude = \"group_rows\")\nlibrary(Rcpp, exclude = \"populate\")\nlibrary(brms, exclude = c(\"ar\", \"mixture\"))\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nLoading 'brms' package (version 2.22.0). Useful instructions\ncan be found by typing help('brms'). A more detailed introduction\nto the package is available through vignette('brms_overview').\n```\n\n\n:::\n\n```{.r .cell-code .hidden}\n#| message: false\n#| warning: false\n\ntheme_set(theme_classic()) \n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n#| output: false\n\ndevtools::source_url(\"https://github.com/jjcurtin/lab_support/blob/main/format_path.R?raw=true\")\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nℹ SHA-1 hash of file is \"a58e57da996d1b70bb9a5b58241325d6fd78890f\"\n```\n\n\n:::\n\n```{.r .cell-code .hidden}\n#| output: false\n\n# CHTC support functions\ndevtools::source_url(\"https://github.com/jjcurtin/lab_support/blob/main/chtc/static_files/fun_chtc.R?raw=true\")\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nℹ SHA-1 hash of file is \"6e9288d22f09da9ec15a1d5c046a0b6736ecce8b\"\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\npath_processed <- format_path(str_c(\"studydata/risk/data_processed/lag\"))\npath_models_lag <- format_path(str_c(\"studydata/risk/models/lag\"))\n```\n:::\n\n\n\n\n### Read in Model Performance Metrics\n\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nauroc_dem_0 <- read_csv(here::here(path_models_lag, \"test_auroc_dem_6_x_5_1week_0_v1_nested.csv\"),\n                      col_types = cols()) |> \n  mutate(fold_num = rep(1:5, 6),\n         repeat_num = c(rep(1, 5), rep(2, 5), rep(3, 5), \n                        rep(4, 5), rep(5, 5), rep(6, 5))) |> \n  select(-outer_split_num)\n\n\nauroc_dem_24 <- read_csv(here::here(path_models_lag, \"test_auroc_dem_6_x_5_1week_24_v1_nested.csv\"),\n                      col_types = cols()) |> \n  mutate(fold_num = rep(1:5, 6),\n         repeat_num = c(rep(1, 5), rep(2, 5), rep(3, 5), \n                        rep(4, 5), rep(5, 5), rep(6, 5))) |> \n  select(-outer_split_num)\n\nauroc_dem_72 <- read_csv(here::here(path_models_lag, \"test_auroc_dem_6_x_5_1week_72_v1_nested.csv\"),\n                      col_types = cols())|> \n  mutate(fold_num = rep(1:5, 6),\n         repeat_num = c(rep(1, 5), rep(2, 5), rep(3, 5), \n                        rep(4, 5), rep(5, 5), rep(6, 5))) |> \n  select(-outer_split_num)\n\nauroc_dem_168 <- read_csv(here::here(path_models_lag, \"test_auroc_dem_6_x_5_1week_168_v1_nested.csv\"),\n                      col_types = cols()) |> \n  mutate(fold_num = rep(1:5, 6),\n         repeat_num = c(rep(1, 5), rep(2, 5), rep(3, 5), \n                        rep(4, 5), rep(5, 5), rep(6, 5))) |> \n  select(-outer_split_num)\n\nauroc_dem_336 <- read_csv(here::here(path_models_lag, \"test_auroc_dem_6_x_5_1week_336_v1_nested.csv\"),\n                      col_types = cols()) |> \n  mutate(fold_num = rep(1:5, 6),\n         repeat_num = c(rep(1, 5), rep(2, 5), rep(3, 5), \n                        rep(4, 5), rep(5, 5), rep(6, 5))) |> \n  select(-outer_split_num)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nauroc_dem_all <- auroc_dem_0 |> \n  mutate(lag = 0) |> \n  bind_rows(auroc_dem_24 |> \n              mutate(lag = 24)) |>\n  bind_rows(auroc_dem_72 |> \n              mutate(lag = 72)) |>\n  bind_rows(auroc_dem_168 |> \n              mutate(lag = 168)) |>\n  bind_rows(auroc_dem_336 |> \n              mutate(lag = 336))\n\nset.seed(101)\n```\n:::\n\n\n\n### Race\n\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\ndata <- auroc_dem_all |> \n  select(id = fold_num, id2 = repeat_num, `not white`, `non-hispanic white` = white, lag) |> \n  pivot_longer(cols = c(`not white`, `non-hispanic white`), names_to = \"race\", values_to = \"auroc\") |> \n  mutate(race = factor(race)) |>\n  glimpse()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 300\nColumns: 5\n$ id    <int> 1, 1, 2, 2, 3, 3, 4, 4, 5, 5, 1, 1, 2, 2, 3, 3, 4, 4, 5, 5, 1, 1…\n$ id2   <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3…\n$ lag   <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ race  <fct> not white, non-hispanic white, not white, non-hispanic white, no…\n$ auroc <dbl> 0.9398942, 0.9117413, 0.3332944, 0.9060419, 0.7679709, 0.8649606…\n```\n\n\n:::\n:::\n\n\n\n\n\nSet priors to `perf_mod()` defaults\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\npriors <- c(\n  prior(normal(2, 1.1), class = \"Intercept\"),\n  \n  prior(normal(0, 2.79), class = \"b\"),\n\n  prior(exponential(2.2), class = \"sigma\")\n)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nmodel_race <- brm(\n  formula = auroc ~ 1 + race + lag + race*lag + (1 | id2/id), # folds nested in repeats\n  data = subset(data, !is.na(auroc)),\n  family = gaussian(link = \"logit\"), # normal distribution w/auroc bounded between 0 and 1\n  chains = 4,\n  prior = priors,\n  control = list(adapt_delta = 0.99), \n  iter = 6000,\n  thin = 10,\n  seed = 123\n)\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nCompiling Stan program...\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nStart sampling\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nSAMPLING FOR MODEL 'anon_model' NOW (CHAIN 1).\nChain 1: \nChain 1: Gradient evaluation took 0.000126 seconds\nChain 1: 1000 transitions using 10 leapfrog steps per transition would take 1.26 seconds.\nChain 1: Adjust your expectations accordingly!\nChain 1: \nChain 1: \nChain 1: Iteration:    1 / 6000 [  0%]  (Warmup)\nChain 1: Iteration:  600 / 6000 [ 10%]  (Warmup)\nChain 1: Iteration: 1200 / 6000 [ 20%]  (Warmup)\nChain 1: Iteration: 1800 / 6000 [ 30%]  (Warmup)\nChain 1: Iteration: 2400 / 6000 [ 40%]  (Warmup)\nChain 1: Iteration: 3000 / 6000 [ 50%]  (Warmup)\nChain 1: Iteration: 3001 / 6000 [ 50%]  (Sampling)\nChain 1: Iteration: 3600 / 6000 [ 60%]  (Sampling)\nChain 1: Iteration: 4200 / 6000 [ 70%]  (Sampling)\nChain 1: Iteration: 4800 / 6000 [ 80%]  (Sampling)\nChain 1: Iteration: 5400 / 6000 [ 90%]  (Sampling)\nChain 1: Iteration: 6000 / 6000 [100%]  (Sampling)\nChain 1: \nChain 1:  Elapsed Time: 31.44 seconds (Warm-up)\nChain 1:                19.974 seconds (Sampling)\nChain 1:                51.414 seconds (Total)\nChain 1: \n\nSAMPLING FOR MODEL 'anon_model' NOW (CHAIN 2).\nChain 2: \nChain 2: Gradient evaluation took 4.5e-05 seconds\nChain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.45 seconds.\nChain 2: Adjust your expectations accordingly!\nChain 2: \nChain 2: \nChain 2: Iteration:    1 / 6000 [  0%]  (Warmup)\nChain 2: Iteration:  600 / 6000 [ 10%]  (Warmup)\nChain 2: Iteration: 1200 / 6000 [ 20%]  (Warmup)\nChain 2: Iteration: 1800 / 6000 [ 30%]  (Warmup)\nChain 2: Iteration: 2400 / 6000 [ 40%]  (Warmup)\nChain 2: Iteration: 3000 / 6000 [ 50%]  (Warmup)\nChain 2: Iteration: 3001 / 6000 [ 50%]  (Sampling)\nChain 2: Iteration: 3600 / 6000 [ 60%]  (Sampling)\nChain 2: Iteration: 4200 / 6000 [ 70%]  (Sampling)\nChain 2: Iteration: 4800 / 6000 [ 80%]  (Sampling)\nChain 2: Iteration: 5400 / 6000 [ 90%]  (Sampling)\nChain 2: Iteration: 6000 / 6000 [100%]  (Sampling)\nChain 2: \nChain 2:  Elapsed Time: 30.709 seconds (Warm-up)\nChain 2:                15.301 seconds (Sampling)\nChain 2:                46.01 seconds (Total)\nChain 2: \n\nSAMPLING FOR MODEL 'anon_model' NOW (CHAIN 3).\nChain 3: \nChain 3: Gradient evaluation took 4.4e-05 seconds\nChain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.44 seconds.\nChain 3: Adjust your expectations accordingly!\nChain 3: \nChain 3: \nChain 3: Iteration:    1 / 6000 [  0%]  (Warmup)\nChain 3: Iteration:  600 / 6000 [ 10%]  (Warmup)\nChain 3: Iteration: 1200 / 6000 [ 20%]  (Warmup)\nChain 3: Iteration: 1800 / 6000 [ 30%]  (Warmup)\nChain 3: Iteration: 2400 / 6000 [ 40%]  (Warmup)\nChain 3: Iteration: 3000 / 6000 [ 50%]  (Warmup)\nChain 3: Iteration: 3001 / 6000 [ 50%]  (Sampling)\nChain 3: Iteration: 3600 / 6000 [ 60%]  (Sampling)\nChain 3: Iteration: 4200 / 6000 [ 70%]  (Sampling)\nChain 3: Iteration: 4800 / 6000 [ 80%]  (Sampling)\nChain 3: Iteration: 5400 / 6000 [ 90%]  (Sampling)\nChain 3: Iteration: 6000 / 6000 [100%]  (Sampling)\nChain 3: \nChain 3:  Elapsed Time: 31.9 seconds (Warm-up)\nChain 3:                20.746 seconds (Sampling)\nChain 3:                52.646 seconds (Total)\nChain 3: \n\nSAMPLING FOR MODEL 'anon_model' NOW (CHAIN 4).\nChain 4: \nChain 4: Gradient evaluation took 4.5e-05 seconds\nChain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.45 seconds.\nChain 4: Adjust your expectations accordingly!\nChain 4: \nChain 4: \nChain 4: Iteration:    1 / 6000 [  0%]  (Warmup)\nChain 4: Iteration:  600 / 6000 [ 10%]  (Warmup)\nChain 4: Iteration: 1200 / 6000 [ 20%]  (Warmup)\nChain 4: Iteration: 1800 / 6000 [ 30%]  (Warmup)\nChain 4: Iteration: 2400 / 6000 [ 40%]  (Warmup)\nChain 4: Iteration: 3000 / 6000 [ 50%]  (Warmup)\nChain 4: Iteration: 3001 / 6000 [ 50%]  (Sampling)\nChain 4: Iteration: 3600 / 6000 [ 60%]  (Sampling)\nChain 4: Iteration: 4200 / 6000 [ 70%]  (Sampling)\nChain 4: Iteration: 4800 / 6000 [ 80%]  (Sampling)\nChain 4: Iteration: 5400 / 6000 [ 90%]  (Sampling)\nChain 4: Iteration: 6000 / 6000 [100%]  (Sampling)\nChain 4: \nChain 4:  Elapsed Time: 32.354 seconds (Warm-up)\nChain 4:                19.479 seconds (Sampling)\nChain 4:                51.833 seconds (Total)\nChain 4: \n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nsummary(model_race) \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n Family: gaussian \n  Links: mu = logit; sigma = identity \nFormula: auroc ~ 1 + race + lag + race * lag + (1 | id2/id) \n   Data: subset(data, !is.na(auroc)) (Number of observations: 283) \n  Draws: 4 chains, each with iter = 6000; warmup = 3000; thin = 10;\n         total post-warmup draws = 1200\n\nMultilevel Hyperparameters:\n~id2 (Number of levels: 6) \n              Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsd(Intercept)     0.21      0.20     0.01     0.75 1.00      916     1213\n\n~id2:id (Number of levels: 30) \n              Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsd(Intercept)     0.94      0.15     0.70     1.28 1.00     1155     1097\n\nRegression Coefficients:\n                 Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nIntercept            3.14      0.27     2.66     3.70 1.01     1225     1127\nracenotwhite        -2.18      0.19    -2.57    -1.85 1.00     1310     1119\nlag                 -0.00      0.00    -0.00     0.00 1.00     1224     1223\nracenotwhite:lag     0.00      0.00    -0.00     0.00 1.00     1180     1165\n\nFurther Distributional Parameters:\n      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsigma     0.08      0.00     0.08     0.09 1.00     1198     1157\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\npp_race <- summary(model_race)$fixed |>\n  as_tibble(rownames = \"coef\") |> \n  select(coef,\n         pp_mean = Estimate, \n         pp_lower = `l-95% CI`, \n         pp_upper = `u-95% CI`) \n```\n:::\n\n\n\n\n\nplot posterior distribution for race effect\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nas.matrix(model_race, variable = \"b_racenotwhite\") |> \n  as_tibble() |> \n  ggplot(aes(x = b_racenotwhite)) +\n  geom_histogram(fill = \"grey\", color = \"black\", bins = 30) +\n  geom_segment(mapping = aes(y = 250, yend = 300, x = pp_mean, xend = pp_mean),\n               data = subset(pp_race, coef == \"racenotwhite\")) +\n  geom_segment(mapping = aes(y = 275, yend = 275, x = pp_lower, xend = pp_upper),\n                data = subset(pp_race, coef == \"racenotwhite\")) +\n  geom_vline(xintercept = 0, linetype =  \"dashed\") \n```\n\n::: {.cell-output-display}\n![](ana_time_subgroup_files/figure-html/unnamed-chunk-8-1.png){width=672}\n:::\n:::\n\n\n\n\nplot posterior distribution for interaction effect\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nas.matrix(model_race, variable = \"b_racenotwhite:lag\") |> \n  ggplot(aes(x = `b_racenotwhite:lag`)) +\n  geom_histogram(fill = \"grey\", color = \"black\", bins = 30) +\n    geom_segment(mapping = aes(y = 100, yend = 150, x = pp_mean, xend = pp_mean),\n               data = subset(pp_race, coef == \"racenotwhite:lag\")) +\n  geom_segment(mapping = aes(y = 125, yend = 125, x = pp_lower, xend = pp_upper),\n                data = subset(pp_race, coef == \"racenotwhite:lag\")) +\n  geom_vline(xintercept = 0, linetype =  \"dashed\") \n```\n\n::: {.cell-output-display}\n![](ana_time_subgroup_files/figure-html/unnamed-chunk-9-1.png){width=672}\n:::\n:::\n\n\n\n\nCheck convergence diagnostics\n\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nbayesplot::mcmc_trace(model_race, pars = c(\"b_Intercept\", \"b_racenotwhite\", \"b_lag\", \"b_racenotwhite:lag\"))\n```\n\n::: {.cell-output-display}\n![](ana_time_subgroup_files/figure-html/unnamed-chunk-10-1.png){width=672}\n:::\n\n```{.r .cell-code .hidden}\nbayesplot::mcmc_acf(model_race, pars = c(\"b_Intercept\", \"b_racenotwhite\", \"b_lag\", \"b_racenotwhite:lag\"))\n```\n\n::: {.cell-output-display}\n![](ana_time_subgroup_files/figure-html/unnamed-chunk-10-2.png){width=672}\n:::\n\n```{.r .cell-code .hidden}\nbayesplot::mcmc_dens(model_race, pars = c(\"b_Intercept\", \"b_racenotwhite\", \"b_lag\", \"b_racenotwhite:lag\"))\n```\n\n::: {.cell-output-display}\n![](ana_time_subgroup_files/figure-html/unnamed-chunk-10-3.png){width=672}\n:::\n:::\n\n\n\nCheck posteriors\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\npp_check(model_race)\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nUsing 10 posterior draws for ppc type 'dens_overlay' by default.\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](ana_time_subgroup_files/figure-html/unnamed-chunk-11-1.png){width=672}\n:::\n:::\n\n\n\n\n### Sex\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\ndata <- auroc_dem_all |> \n  select(id = fold_num, id2 = repeat_num, female, male, lag) |> \n  pivot_longer(cols = c(female, male), names_to = \"sex\", values_to = \"auroc\") |>\n  mutate(sex = factor(sex, levels = c(\"male\", \"female\"))) |>\n  glimpse()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 300\nColumns: 5\n$ id    <int> 1, 1, 2, 2, 3, 3, 4, 4, 5, 5, 1, 1, 2, 2, 3, 3, 4, 4, 5, 5, 1, 1…\n$ id2   <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3…\n$ lag   <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ sex   <fct> female, male, female, male, female, male, female, male, female, …\n$ auroc <dbl> 0.8717134, 0.9537088, 0.7873624, 0.9585205, 0.8616866, 0.8588775…\n```\n\n\n:::\n\n```{.r .cell-code .hidden}\nmodel_sex <-brm(\n  formula = auroc ~ 1 + sex + lag + sex*lag + (1 | id2/id), # folds nested in repeats\n  data = subset(data, !is.na(auroc)),\n  family = gaussian(link = \"logit\"), # normal distribution w/auroc bounded between 0 and 1\n  chains = 4,\n  prior = priors,\n  control = list(adapt_delta = 0.99), \n  iter = 6000,\n  thin = 10,\n  seed = 123\n)\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nCompiling Stan program...\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nStart sampling\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nSAMPLING FOR MODEL 'anon_model' NOW (CHAIN 1).\nChain 1: \nChain 1: Gradient evaluation took 9.6e-05 seconds\nChain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.96 seconds.\nChain 1: Adjust your expectations accordingly!\nChain 1: \nChain 1: \nChain 1: Iteration:    1 / 6000 [  0%]  (Warmup)\nChain 1: Iteration:  600 / 6000 [ 10%]  (Warmup)\nChain 1: Iteration: 1200 / 6000 [ 20%]  (Warmup)\nChain 1: Iteration: 1800 / 6000 [ 30%]  (Warmup)\nChain 1: Iteration: 2400 / 6000 [ 40%]  (Warmup)\nChain 1: Iteration: 3000 / 6000 [ 50%]  (Warmup)\nChain 1: Iteration: 3001 / 6000 [ 50%]  (Sampling)\nChain 1: Iteration: 3600 / 6000 [ 60%]  (Sampling)\nChain 1: Iteration: 4200 / 6000 [ 70%]  (Sampling)\nChain 1: Iteration: 4800 / 6000 [ 80%]  (Sampling)\nChain 1: Iteration: 5400 / 6000 [ 90%]  (Sampling)\nChain 1: Iteration: 6000 / 6000 [100%]  (Sampling)\nChain 1: \nChain 1:  Elapsed Time: 57.991 seconds (Warm-up)\nChain 1:                19.518 seconds (Sampling)\nChain 1:                77.509 seconds (Total)\nChain 1: \n\nSAMPLING FOR MODEL 'anon_model' NOW (CHAIN 2).\nChain 2: \nChain 2: Gradient evaluation took 4.8e-05 seconds\nChain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.48 seconds.\nChain 2: Adjust your expectations accordingly!\nChain 2: \nChain 2: \nChain 2: Iteration:    1 / 6000 [  0%]  (Warmup)\nChain 2: Iteration:  600 / 6000 [ 10%]  (Warmup)\nChain 2: Iteration: 1200 / 6000 [ 20%]  (Warmup)\nChain 2: Iteration: 1800 / 6000 [ 30%]  (Warmup)\nChain 2: Iteration: 2400 / 6000 [ 40%]  (Warmup)\nChain 2: Iteration: 3000 / 6000 [ 50%]  (Warmup)\nChain 2: Iteration: 3001 / 6000 [ 50%]  (Sampling)\nChain 2: Iteration: 3600 / 6000 [ 60%]  (Sampling)\nChain 2: Iteration: 4200 / 6000 [ 70%]  (Sampling)\nChain 2: Iteration: 4800 / 6000 [ 80%]  (Sampling)\nChain 2: Iteration: 5400 / 6000 [ 90%]  (Sampling)\nChain 2: Iteration: 6000 / 6000 [100%]  (Sampling)\nChain 2: \nChain 2:  Elapsed Time: 59.532 seconds (Warm-up)\nChain 2:                24.912 seconds (Sampling)\nChain 2:                84.444 seconds (Total)\nChain 2: \n\nSAMPLING FOR MODEL 'anon_model' NOW (CHAIN 3).\nChain 3: \nChain 3: Gradient evaluation took 4.7e-05 seconds\nChain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.47 seconds.\nChain 3: Adjust your expectations accordingly!\nChain 3: \nChain 3: \nChain 3: Iteration:    1 / 6000 [  0%]  (Warmup)\nChain 3: Iteration:  600 / 6000 [ 10%]  (Warmup)\nChain 3: Iteration: 1200 / 6000 [ 20%]  (Warmup)\nChain 3: Iteration: 1800 / 6000 [ 30%]  (Warmup)\nChain 3: Iteration: 2400 / 6000 [ 40%]  (Warmup)\nChain 3: Iteration: 3000 / 6000 [ 50%]  (Warmup)\nChain 3: Iteration: 3001 / 6000 [ 50%]  (Sampling)\nChain 3: Iteration: 3600 / 6000 [ 60%]  (Sampling)\nChain 3: Iteration: 4200 / 6000 [ 70%]  (Sampling)\nChain 3: Iteration: 4800 / 6000 [ 80%]  (Sampling)\nChain 3: Iteration: 5400 / 6000 [ 90%]  (Sampling)\nChain 3: Iteration: 6000 / 6000 [100%]  (Sampling)\nChain 3: \nChain 3:  Elapsed Time: 58.229 seconds (Warm-up)\nChain 3:                21.251 seconds (Sampling)\nChain 3:                79.48 seconds (Total)\nChain 3: \n\nSAMPLING FOR MODEL 'anon_model' NOW (CHAIN 4).\nChain 4: \nChain 4: Gradient evaluation took 4.8e-05 seconds\nChain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.48 seconds.\nChain 4: Adjust your expectations accordingly!\nChain 4: \nChain 4: \nChain 4: Iteration:    1 / 6000 [  0%]  (Warmup)\nChain 4: Iteration:  600 / 6000 [ 10%]  (Warmup)\nChain 4: Iteration: 1200 / 6000 [ 20%]  (Warmup)\nChain 4: Iteration: 1800 / 6000 [ 30%]  (Warmup)\nChain 4: Iteration: 2400 / 6000 [ 40%]  (Warmup)\nChain 4: Iteration: 3000 / 6000 [ 50%]  (Warmup)\nChain 4: Iteration: 3001 / 6000 [ 50%]  (Sampling)\nChain 4: Iteration: 3600 / 6000 [ 60%]  (Sampling)\nChain 4: Iteration: 4200 / 6000 [ 70%]  (Sampling)\nChain 4: Iteration: 4800 / 6000 [ 80%]  (Sampling)\nChain 4: Iteration: 5400 / 6000 [ 90%]  (Sampling)\nChain 4: Iteration: 6000 / 6000 [100%]  (Sampling)\nChain 4: \nChain 4:  Elapsed Time: 56.683 seconds (Warm-up)\nChain 4:                25.977 seconds (Sampling)\nChain 4:                82.66 seconds (Total)\nChain 4: \n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nsummary(model_sex)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n Family: gaussian \n  Links: mu = logit; sigma = identity \nFormula: auroc ~ 1 + sex + lag + sex * lag + (1 | id2/id) \n   Data: subset(data, !is.na(auroc)) (Number of observations: 300) \n  Draws: 4 chains, each with iter = 6000; warmup = 3000; thin = 10;\n         total post-warmup draws = 1200\n\nMultilevel Hyperparameters:\n~id2 (Number of levels: 6) \n              Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsd(Intercept)     0.08      0.07     0.00     0.28 1.00     1080     1131\n\n~id2:id (Number of levels: 30) \n              Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsd(Intercept)     0.28      0.05     0.21     0.38 1.00     1272     1174\n\nRegression Coefficients:\n              Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nIntercept         2.47      0.08     2.30     2.63 1.00     1256     1223\nsexfemale        -0.70      0.06    -0.81    -0.59 1.00     1246     1120\nlag              -0.00      0.00    -0.00    -0.00 1.00     1150      928\nsexfemale:lag    -0.00      0.00    -0.00    -0.00 1.00     1176     1181\n\nFurther Distributional Parameters:\n      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsigma     0.03      0.00     0.03     0.04 1.00     1093     1062\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\npp_sex <- summary(model_sex)$fixed |>\n  as_tibble(rownames = \"coef\") |> \n  select(coef,\n         pp_mean = Estimate, \n         pp_lower = `l-95% CI`, \n         pp_upper = `u-95% CI`) \n```\n:::\n\n\n\nplot posterior distribution for sex effect\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nas.matrix(model_sex, variable = \"b_sexfemale\") |> \n  as_tibble() |> \n  ggplot(aes(x = b_sexfemale)) +\n  geom_histogram(fill = \"grey\", color = \"black\", bins = 30) +\n  geom_segment(mapping = aes(y = 300, yend = 350, x = pp_mean, xend = pp_mean),\n               data = subset(pp_sex, coef == \"sexfemale\")) +\n  geom_segment(mapping = aes(y = 325, yend = 325, x = pp_lower, xend = pp_upper),\n                data = subset(pp_sex, coef == \"sexfemale\")) +\n  geom_vline(xintercept = 0, linetype =  \"dashed\") \n```\n\n::: {.cell-output-display}\n![](ana_time_subgroup_files/figure-html/unnamed-chunk-15-1.png){width=672}\n:::\n:::\n\n\n\n\nplot posterior distribution for interaction effect\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nas.matrix(model_sex, variable = \"b_sexfemale:lag\") |> \n  ggplot(aes(x = `b_sexfemale:lag`)) +\n  geom_histogram(fill = \"grey\", color = \"black\", bins = 30) +\n    geom_segment(mapping = aes(y = 100, yend = 150, x = pp_mean, xend = pp_mean),\n               data = subset(pp_sex, coef == \"sexfemale:lag\")) +\n  geom_segment(mapping = aes(y = 125, yend = 125, x = pp_lower, xend = pp_upper),\n                data = subset(pp_sex, coef == \"sexfemale:lag\")) +\n  geom_vline(xintercept = 0, linetype =  \"dashed\") \n```\n\n::: {.cell-output-display}\n![](ana_time_subgroup_files/figure-html/unnamed-chunk-16-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nbayesplot::mcmc_trace(model_sex, pars = c(\"b_Intercept\", \"b_sexfemale\", \"b_lag\", \"b_sexfemale:lag\"))\n```\n\n::: {.cell-output-display}\n![](ana_time_subgroup_files/figure-html/unnamed-chunk-17-1.png){width=672}\n:::\n\n```{.r .cell-code .hidden}\nbayesplot::mcmc_acf(model_sex, pars = c(\"b_Intercept\", \"b_sexfemale\", \"b_lag\", \"b_sexfemale:lag\"))\n```\n\n::: {.cell-output-display}\n![](ana_time_subgroup_files/figure-html/unnamed-chunk-17-2.png){width=672}\n:::\n\n```{.r .cell-code .hidden}\nbayesplot::mcmc_dens(model_sex, pars = c(\"b_Intercept\", \"b_sexfemale\", \"b_lag\", \"b_sexfemale:lag\"))\n```\n\n::: {.cell-output-display}\n![](ana_time_subgroup_files/figure-html/unnamed-chunk-17-3.png){width=672}\n:::\n:::\n\n\n\nCheck posteriors\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\npp_check(model_sex)\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nUsing 10 posterior draws for ppc type 'dens_overlay' by default.\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](ana_time_subgroup_files/figure-html/unnamed-chunk-18-1.png){width=672}\n:::\n:::\n\n\n\n### Income\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\ndata <- auroc_dem_all |> \n  select(id = fold_num, id2 = repeat_num, `above poverty`, `below poverty`, lag) |> \n  pivot_longer(cols = c(`above poverty`, `below poverty`), names_to = \"income\", \n               values_to = \"auroc\") |>\n  mutate(income = factor(income)) |>\n  glimpse()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 300\nColumns: 5\n$ id     <int> 1, 1, 2, 2, 3, 3, 4, 4, 5, 5, 1, 1, 2, 2, 3, 3, 4, 4, 5, 5, 1, …\n$ id2    <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, …\n$ lag    <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ income <fct> above poverty, below poverty, above poverty, below poverty, abo…\n$ auroc  <dbl> 0.9044134, NA, 0.8898187, 0.9129438, 0.8826674, 0.5045085, 0.91…\n```\n\n\n:::\n\n```{.r .cell-code .hidden}\nmodel_income <- brm(\n  formula = auroc ~ 1 + income + lag + income*lag + (1 | id2/id), # folds nested in repeats\n  data = subset(data, !is.na(auroc)),\n  family = gaussian(link = \"logit\"), # normal distribution w/auroc bounded between 0 and 1\n  chains = 4,\n  prior = priors,\n  control = list(adapt_delta = 0.999), \n  iter = 6000,\n  thin = 10,\n  seed = 123\n)\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nCompiling Stan program...\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nStart sampling\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nSAMPLING FOR MODEL 'anon_model' NOW (CHAIN 1).\nChain 1: \nChain 1: Gradient evaluation took 0.000104 seconds\nChain 1: 1000 transitions using 10 leapfrog steps per transition would take 1.04 seconds.\nChain 1: Adjust your expectations accordingly!\nChain 1: \nChain 1: \nChain 1: Iteration:    1 / 6000 [  0%]  (Warmup)\nChain 1: Iteration:  600 / 6000 [ 10%]  (Warmup)\nChain 1: Iteration: 1200 / 6000 [ 20%]  (Warmup)\nChain 1: Iteration: 1800 / 6000 [ 30%]  (Warmup)\nChain 1: Iteration: 2400 / 6000 [ 40%]  (Warmup)\nChain 1: Iteration: 3000 / 6000 [ 50%]  (Warmup)\nChain 1: Iteration: 3001 / 6000 [ 50%]  (Sampling)\nChain 1: Iteration: 3600 / 6000 [ 60%]  (Sampling)\nChain 1: Iteration: 4200 / 6000 [ 70%]  (Sampling)\nChain 1: Iteration: 4800 / 6000 [ 80%]  (Sampling)\nChain 1: Iteration: 5400 / 6000 [ 90%]  (Sampling)\nChain 1: Iteration: 6000 / 6000 [100%]  (Sampling)\nChain 1: \nChain 1:  Elapsed Time: 55.327 seconds (Warm-up)\nChain 1:                42.913 seconds (Sampling)\nChain 1:                98.24 seconds (Total)\nChain 1: \n\nSAMPLING FOR MODEL 'anon_model' NOW (CHAIN 2).\nChain 2: \nChain 2: Gradient evaluation took 4.4e-05 seconds\nChain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.44 seconds.\nChain 2: Adjust your expectations accordingly!\nChain 2: \nChain 2: \nChain 2: Iteration:    1 / 6000 [  0%]  (Warmup)\nChain 2: Iteration:  600 / 6000 [ 10%]  (Warmup)\nChain 2: Iteration: 1200 / 6000 [ 20%]  (Warmup)\nChain 2: Iteration: 1800 / 6000 [ 30%]  (Warmup)\nChain 2: Iteration: 2400 / 6000 [ 40%]  (Warmup)\nChain 2: Iteration: 3000 / 6000 [ 50%]  (Warmup)\nChain 2: Iteration: 3001 / 6000 [ 50%]  (Sampling)\nChain 2: Iteration: 3600 / 6000 [ 60%]  (Sampling)\nChain 2: Iteration: 4200 / 6000 [ 70%]  (Sampling)\nChain 2: Iteration: 4800 / 6000 [ 80%]  (Sampling)\nChain 2: Iteration: 5400 / 6000 [ 90%]  (Sampling)\nChain 2: Iteration: 6000 / 6000 [100%]  (Sampling)\nChain 2: \nChain 2:  Elapsed Time: 52.576 seconds (Warm-up)\nChain 2:                124.554 seconds (Sampling)\nChain 2:                177.13 seconds (Total)\nChain 2: \n\nSAMPLING FOR MODEL 'anon_model' NOW (CHAIN 3).\nChain 3: \nChain 3: Gradient evaluation took 4.4e-05 seconds\nChain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.44 seconds.\nChain 3: Adjust your expectations accordingly!\nChain 3: \nChain 3: \nChain 3: Iteration:    1 / 6000 [  0%]  (Warmup)\nChain 3: Iteration:  600 / 6000 [ 10%]  (Warmup)\nChain 3: Iteration: 1200 / 6000 [ 20%]  (Warmup)\nChain 3: Iteration: 1800 / 6000 [ 30%]  (Warmup)\nChain 3: Iteration: 2400 / 6000 [ 40%]  (Warmup)\nChain 3: Iteration: 3000 / 6000 [ 50%]  (Warmup)\nChain 3: Iteration: 3001 / 6000 [ 50%]  (Sampling)\nChain 3: Iteration: 3600 / 6000 [ 60%]  (Sampling)\nChain 3: Iteration: 4200 / 6000 [ 70%]  (Sampling)\nChain 3: Iteration: 4800 / 6000 [ 80%]  (Sampling)\nChain 3: Iteration: 5400 / 6000 [ 90%]  (Sampling)\nChain 3: Iteration: 6000 / 6000 [100%]  (Sampling)\nChain 3: \nChain 3:  Elapsed Time: 51.722 seconds (Warm-up)\nChain 3:                21.095 seconds (Sampling)\nChain 3:                72.817 seconds (Total)\nChain 3: \n\nSAMPLING FOR MODEL 'anon_model' NOW (CHAIN 4).\nChain 4: \nChain 4: Gradient evaluation took 4.4e-05 seconds\nChain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.44 seconds.\nChain 4: Adjust your expectations accordingly!\nChain 4: \nChain 4: \nChain 4: Iteration:    1 / 6000 [  0%]  (Warmup)\nChain 4: Iteration:  600 / 6000 [ 10%]  (Warmup)\nChain 4: Iteration: 1200 / 6000 [ 20%]  (Warmup)\nChain 4: Iteration: 1800 / 6000 [ 30%]  (Warmup)\nChain 4: Iteration: 2400 / 6000 [ 40%]  (Warmup)\nChain 4: Iteration: 3000 / 6000 [ 50%]  (Warmup)\nChain 4: Iteration: 3001 / 6000 [ 50%]  (Sampling)\nChain 4: Iteration: 3600 / 6000 [ 60%]  (Sampling)\nChain 4: Iteration: 4200 / 6000 [ 70%]  (Sampling)\nChain 4: Iteration: 4800 / 6000 [ 80%]  (Sampling)\nChain 4: Iteration: 5400 / 6000 [ 90%]  (Sampling)\nChain 4: Iteration: 6000 / 6000 [100%]  (Sampling)\nChain 4: \nChain 4:  Elapsed Time: 51.558 seconds (Warm-up)\nChain 4:                36.859 seconds (Sampling)\nChain 4:                88.417 seconds (Total)\nChain 4: \n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nWarning: There were 202 transitions after warmup that exceeded the maximum treedepth. Increase max_treedepth above 10. See\nhttps://mc-stan.org/misc/warnings.html#maximum-treedepth-exceeded\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nWarning: Examine the pairs() plot to diagnose sampling problems\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nsummary(model_income)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n Family: gaussian \n  Links: mu = logit; sigma = identity \nFormula: auroc ~ 1 + income + lag + income * lag + (1 | id2/id) \n   Data: subset(data, !is.na(auroc)) (Number of observations: 280) \n  Draws: 4 chains, each with iter = 6000; warmup = 3000; thin = 10;\n         total post-warmup draws = 1200\n\nMultilevel Hyperparameters:\n~id2 (Number of levels: 6) \n              Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsd(Intercept)     0.24      0.21     0.01     0.82 1.00     1054     1071\n\n~id2:id (Number of levels: 30) \n              Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsd(Intercept)     0.64      0.11     0.48     0.89 1.00      992      870\n\nRegression Coefficients:\n                       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS\nIntercept                  2.59      0.21     2.22     2.99 1.00     1197\nincomebelowpoverty        -1.36      0.12    -1.60    -1.13 1.00     1118\nlag                       -0.00      0.00    -0.00    -0.00 1.00     1208\nincomebelowpoverty:lag    -0.00      0.00    -0.00     0.00 1.00     1256\n                       Tail_ESS\nIntercept                  1211\nincomebelowpoverty         1123\nlag                        1091\nincomebelowpoverty:lag     1185\n\nFurther Distributional Parameters:\n      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsigma     0.07      0.00     0.07     0.08 1.00     1196      899\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\npp_income <- summary(model_income)$fixed |>\n  as_tibble(rownames = \"coef\") |> \n  select(coef,\n         pp_mean = Estimate, \n         pp_lower = `l-95% CI`, \n         pp_upper = `u-95% CI`) \n```\n:::\n\n\n\nplot posterior distribution for income effect\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nas.matrix(model_income, variable = \"b_incomebelowpoverty\") |> \n  as_tibble() |> \n  ggplot(aes(x = b_incomebelowpoverty)) +\n  geom_histogram(fill = \"grey\", color = \"black\", bins = 30) +\n  geom_segment(mapping = aes(y = 225, yend = 275, x = pp_mean, xend = pp_mean),\n               data = subset(pp_income, coef == \"incomebelowpoverty\")) +\n  geom_segment(mapping = aes(y = 250, yend = 250, x = pp_lower, xend = pp_upper),\n                data = subset(pp_income, coef == \"incomebelowpoverty\")) +\n  geom_vline(xintercept = 0, linetype =  \"dashed\") \n```\n\n::: {.cell-output-display}\n![](ana_time_subgroup_files/figure-html/unnamed-chunk-22-1.png){width=672}\n:::\n:::\n\n\n\n\nplot posterior distribution for interaction effect\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nas.matrix(model_income, variable = \"b_incomebelowpoverty:lag\") |> \n  ggplot(aes(x = `b_incomebelowpoverty:lag`)) +\n  geom_histogram(fill = \"grey\", color = \"black\", bins = 30) +\n  geom_segment(mapping = aes(y = 125, yend = 175, x = pp_mean, xend = pp_mean),\n               data = subset(pp_income, coef == \"incomebelowpoverty:lag\")) +\n  geom_segment(mapping = aes(y = 150, yend = 150, x = pp_lower, xend = pp_upper),\n                data = subset(pp_income, coef == \"incomebelowpoverty:lag\")) +\n  geom_vline(xintercept = 0, linetype =  \"dashed\") \n```\n\n::: {.cell-output-display}\n![](ana_time_subgroup_files/figure-html/unnamed-chunk-23-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nbayesplot::mcmc_trace(model_income, pars = c(\"b_Intercept\", \"b_incomebelowpoverty\", \"b_lag\", \"b_incomebelowpoverty:lag\"))\n```\n\n::: {.cell-output-display}\n![](ana_time_subgroup_files/figure-html/unnamed-chunk-24-1.png){width=672}\n:::\n\n```{.r .cell-code .hidden}\nbayesplot::mcmc_acf(model_income, pars = c(\"b_Intercept\", \"b_incomebelowpoverty\", \"b_lag\", \"b_incomebelowpoverty:lag\"))\n```\n\n::: {.cell-output-display}\n![](ana_time_subgroup_files/figure-html/unnamed-chunk-24-2.png){width=672}\n:::\n\n```{.r .cell-code .hidden}\nbayesplot::mcmc_dens(model_income, pars = c(\"b_Intercept\", \"b_incomebelowpoverty\", \"b_lag\", \"b_incomebelowpoverty:lag\"))\n```\n\n::: {.cell-output-display}\n![](ana_time_subgroup_files/figure-html/unnamed-chunk-24-3.png){width=672}\n:::\n:::\n\n\n\nCheck posteriors\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\npp_check(model_income)\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nUsing 10 posterior draws for ppc type 'dens_overlay' by default.\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](ana_time_subgroup_files/figure-html/unnamed-chunk-25-1.png){width=672}\n:::\n:::",
    "supporting": [
      "ana_time_subgroup_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}