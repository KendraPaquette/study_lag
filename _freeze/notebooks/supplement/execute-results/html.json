{
  "hash": "b7731aeea0530b08cf1c3a4b1e1a41f8",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Supplemental Material\"\nsubtitle: \"Lagged Predictions of Next Week Alcohol Use for Precision Mental Health Support\"\nauthor: \"Kendra Wyant, Gaylen E. Fronk, Jiachen Yu, and John J. Curtin\"\ndate: last-modified\nnumber-sections: true\nformat: \n  html: \n    embed-resources: true\n    toc: true \n    toc_depth: 5\neditor_options: \n  chunk_output_type: console\n---\n\n\nThis file contains the supplemental materials for *Lagged Predictions of Next Week Alcohol Use for Precision Mental Health Support*. It includes a transparency report and all supplemental figures and tables. Additional materials are made available on our study's OSF page ([https://osf.io/xta67/](https://osf.io/xta67/)).   \n\n-----\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n#| echo: false\n\nsuppressPackageStartupMessages(library(tidyverse))\nsuppressPackageStartupMessages(source(\"https://github.com/jjcurtin/lab_support/blob/main/format_path.R?raw=true\"))\nsuppressPackageStartupMessages(library(tidyposterior))\n\n\ntheme_set(theme_classic())\n\noptions(knitr.kable.NA = '')\n\npath_models_lag <- format_path(str_c(\"studydata/risk/models/lag\"))\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n#| echo: false\n\npp_tidy <- read_csv(here::here(path_models_lag, \"pp_tidy.csv\"), \n                                 show_col_types = FALSE) \n\nci <- read_csv(here::here(path_models_lag, \"test_metrics_all_pp_perf.csv\"), \n                                 show_col_types = FALSE) |> \n  mutate(model = factor(model, levels = c(\"0 lag\", \"24 lag\", \"72 lag\", \"168 lag\", \"336 lag\"),\n                        labels = c(\"0 hours\", \"24 hours\", \"72 hours\", \"168 hours\", \"336 hours\")))\n\npp_dem <- read_csv(here::here(path_models_lag, \"pp_dem_all.csv\"), \n                                 show_col_types = FALSE)\n\npp_dem_contrast <- read_csv(here::here(path_models_lag, \"pp_dem_contrast_all.csv\"), \n                                 show_col_types = FALSE)\n```\n:::\n\n\n## Transparency Report 1.0 (full, 36 items; Aczel et al., 2019)\n\n**Manuscript Title:** Lagged Predictions of Next Week Alcohol Use for Precision Mental Health Support   \n**Authors:** Kendra Wyant, Gaylen E. Fronk, Jiachen Yu, and John J. Curtin   \n**Corresponding author’s email address:** jjcurtin@wisc.edu   \n**Link to Project Repository:** [https://osf.io/xta67/](https://osf.io/xta67/)      \n\n### Preregistration Section   \n- Prior to analyzing the complete data set, a time-stamped preregistration was posted in an independent, third-party registry for the data analysis plan: Yes  \n\nComments about your Preregistration: We pre-registered our data analytic strategy on OSF.   \n\n### Methods Section\nThe manuscript fully describes…    \n\n- the rationale for the sample size used (e.g., an a priori power analysis): Yes  \n- how participants were recruited: Yes  \n- how participants were selected (e.g., eligibility criteria): Yes  \n- what compensation was offered for participation: Yes  \n- how participant dropout was handled (e.g., replaced, omitted, etc): Yes  \n- how participants were assigned to conditions: N/A.  There are no conditions.  \n- how stimulus materials were randomized: N/A.    \n- whether (and, if so, how) participants, experimenters, and data-analysts were kept naive to potentially biasing information: N/A.  This is an observations study that does not include analysis of group or manipulations.   There were no study conditions to blind.   \n- the study design, procedures, and materials to allow independent replication: Yes   \n-\tthe measures of interest (e.g., friendliness): Yes   \n-\tall operationalizations for the measures of interest (e.g., a questionnaire measuring friendliness): Yes   \n\n### Results and Discussion Section\nThe manuscript…  \n\n-\tdistinguishes explicitly between “confirmatory” (i.e., prespecified) and “exploratory” (i.e., not prespecified) analyses: All analyses were pre-registered.\n-\tdescribes how violations of statistical assumptions were handled: No  \n-\tjustifies all statistical choices (e.g., including or excluding covariates; applying or not applying transformations; use of multi-level models vs. ANOVA): Yes  \n-\treports the sample size for each cell of the design: Yes  \n-\treports how incomplete or missing data were handled: Yes  \n-\tpresents protocols for data preprocessing (e.g., cleaning, discarding of cases and items, normalizing, smoothing, artifact correction): Yes  \n\n### Data, Code, and Materials Availability Section\nThe following have been made publicly available…  \n\n-\tthe (processed) data, on which the analyses of the manuscript were based: Yes   \n-\tall code and software (that is not copyright protected): Yes   \n-\tall instructions, stimuli, and test materials (that are not copyright protected): Yes   \n-\tAre the data properly archived (i.e., would a graduate student with relevant background knowledge be able to identify each variable and reproduce the analysis): Yes   \n-\tThe manuscript includes a statement concerning the availability and location of all research items, including data, materials, and code relevant to the study: Yes   \n\n\n\\newpage\n\n## Supplemental Methods\n\n### Feature Importance\n\nWe calculated Shapley values in log-odds units for binary classification models from the 30 test sets to provide a description of the importance of categories of features across our five models [@lundbergUnifiedApproachInterpreting2017]. We averaged the three Shapley values for each observation for each feature (i.e., across the three repeats) to increase their stability. An inherent property of Shapley values is their additivity, allowing us to combine features into feature categories. We created separate feature categories for each of the nine EMA questions, the rates of past alcohol use and missing surveys, the time of day and day of the week of the start of the prediction window, and the seven demographic variables included in the models. We calculated the local (i.e., for each observation) importance for each category of features by adding Shapley values across all features in a category, separately for each observation. We calculated global importance for each feature category by averaging the absolute value of the Shapley values of all features in the category across all observations. These local and global importance scores based on Shapley values allow us to contextualize relative feature importance for each model.\n\n## Supplemental Results\n\n### Feature Importance\n\nThe top three globally important (i.e., highest mean |Shapley value|) feature categories for all models were past use, future efficacy, and craving (Figure S2). Future risky situations were also globally important across models. This category was ranked as the 4th most important feature across lagged models (24, 72, 168, and 336 hours). For the immediate model (0 hour lag), past risky situations were ranked as the 4th most important feature category and future risky situations was ranked as the fifth most important. Income was the only demographic feature that emerged as having high global importance for lapse prediction (in top 6 for all models). See Table S1 for a table of feature categories ranked by global importance for each model.    \n\nSee Figure S3 for a local feature importance plots for each model. Future abstinence efficacy, future risky situations, and income appear to have a linear relationship to lapse prediction. Higher efficacy, fewer future risky situations, and higher income were associated with a lower likelihood that the model would predict a lapse. In Figure S4, we plot the relationship between Shapley value and feature score individually for our overall top five features by model.\n\n\n## Supplemental Figures\n\n### Figure S1: Full Posterior Distributions for auROC by Model\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n#| echo: false\npp_tidy |> \n  mutate(model = factor(model, levels = c(\"lag0\", \"lag24\", \"lag72\", \"lag168\", \"lag336\"),\n                        labels = c(\"0 hours\", \"24 hours\", \"72 hours\", \"168 hours\", \"336 hours\"))) |>\n  ggplot() + \n  geom_histogram(aes(x = posterior), fill = \"light grey\", color = \"black\", alpha = .4, \n                 bins = 30) +\n  geom_segment(mapping = aes(y = 1200, yend = 1600, x = pp_median, xend = pp_median),\n               data = ci) +\n  geom_segment(mapping = aes(y = 1400, yend = 1400, x = pp_lower, xend = pp_upper),\n                data = ci) +\n  facet_wrap(~model, ncol = 1) +\n  scale_y_continuous(\"Posterior Probability\", breaks = c(0, 500, 1000, 1500)) +\n  xlab(\"Area Under ROC Curve\") +\n  theme_classic() +\n  theme(legend.position = \"none\")\n```\n\n::: {.cell-output-display}\n![](supplement_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n:::\n\n\n### Figure S2: Global Shapley Plot\n\n\nRead in data\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nglobal_all <- read_rds(here::here(path_models_lag, \"shap_global_all.rds\")) |> \n   filter(!variable_grp %in% c(\"day of week (other)\", \"time of day (other)\")) |> \n  mutate(variable_grp = str_remove(variable_grp, \"(EMA item)\"),\n          variable_grp = str_remove(variable_grp, \"(demographic)\"),\n          variable_grp = str_remove(variable_grp, \"(other)\"),\n        variable_grp = str_remove(variable_grp, \"[[:punct:]][[:punct:]]\")) |> \n   mutate(variable_grp = reorder(variable_grp, mean_value, sum),\n          model = factor(model, c(\"0 lag\", \"24 lag\", \"72 lag\", \"168 lag\", \"336 lag\")))\n\nshap_levels <- global_all |>\n  mutate(variable_grp = reorder(variable_grp, mean_value, sum)) |>\n  pull(variable_grp) |>\n  levels()\n```\n:::\n\n\n\nGlobal shapley pannel\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\ncolor_codes <- c(\"#240e31\",\"#75f3d3\", \"#458892\", \"#751c6d\", \"#cb6bce\")\n\npanel_shap_global <- global_all |>\n   mutate(model = factor(model, levels = c(\"336 lag\", \"168 lag\", \"72 lag\", \"24 lag\", \"0 lag\" ),\n                         labels = c(\"336 hours\", \"168 hours\", \"72 hours\", \"24 hours\", \"0 hours\" ))) |> \n  ggplot() +\n  geom_bar(aes(x = variable_grp, y = mean_value, fill = model), stat = \"identity\") +\n  ylab(\"Mean(|Shapley Value|)\") +\n  xlab(\"\") +\n  labs(fill = \"Model Lag\") +\n  scale_color_manual(values = color_codes) +\n  scale_fill_manual(values = color_codes) +\n  theme(axis.text=element_text(size=9.5),\n        panel.border = element_rect(colour = \"black\", fill = NA, linewidth = 1),\n        legend.position = \"right\",\n        # legend.key.size = unit(.3, 'cm'),\n        ) +\n  coord_flip()\n```\n:::\n\n::: {#cell-fig-shap .cell}\n\n```{.r .cell-code .hidden}\n#| label: fig-shap\n#| fig-cap: \"Global importance (mean |Shapley value|) for feature categories for each model. Feature categories are ordered by their aggregate global importance (i.e., total bar length) across the five models. The importance of each feature category for specific models is displayed separately by color.\"\n#| fig-height: 5.5\n#| fig-width: 7\n\npanel_shap_global\n```\n\n::: {.cell-output-display}\n![Global importance (mean |Shapley value|) for feature categories for each model. Feature categories are ordered by their aggregate global importance (i.e., total bar length) across the five models. The importance of each feature category for specific models is displayed separately by color.](supplement_files/figure-html/fig-shap-1.png){#fig-shap width=672}\n:::\n:::\n\n\n\n### Figure S3: Local Shapley Plots by Model\n\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n#| echo: false\n\nshap_feat_0 <- read_rds(here::here(path_models_lag, \"outer_shapsgrp_with_features_downsized_1week_0_v1_nested_main.rds\")) |> \n  mutate(variable_grp = factor(variable_grp, levels = shap_levels),\n         feature_score_z_mean = if_else(variable_grp == \"future efficacy \",\n                                        feature_score_z_mean * (-1),\n                                        feature_score_z_mean))\n  \nshap_feat_24 <- read_rds(here::here(path_models_lag, \"outer_shapsgrp_with_features_downsized_1week_24_v1_nested_main.rds\")) |> \n  mutate(variable_grp = factor(variable_grp, levels = shap_levels),\n         feature_score_z_mean = if_else(variable_grp == \"future efficacy \",\n                                        feature_score_z_mean * -1,\n                                        feature_score_z_mean))\n\nshap_feat_72 <- read_rds(here::here(path_models_lag, \"outer_shapsgrp_with_features_downsized_1week_72_v1_nested_main.rds\")) |> \n  mutate(variable_grp = factor(variable_grp, levels = shap_levels),\n         feature_score_z_mean = if_else(variable_grp == \"future efficacy \",\n                                        feature_score_z_mean * -1,\n                                        feature_score_z_mean))\nshap_feat_168 <- read_rds(here::here(path_models_lag, \"outer_shapsgrp_with_features_downsized_1week_168_v1_nested_main.rds\")) |> \n  mutate(variable_grp = factor(variable_grp, levels = shap_levels),\n         feature_score_z_mean = if_else(variable_grp == \"future efficacy \",\n                                        feature_score_z_mean * -1,\n                                        feature_score_z_mean))\n\nshap_feat_336 <- read_rds(here::here(path_models_lag, \"outer_shapsgrp_with_features_downsized_1week_336_v1_nested_main.rds\")) |> \n  mutate(variable_grp = factor(variable_grp, levels = shap_levels),\n         feature_score_z_mean = if_else(variable_grp == \"future efficacy \",\n                                        feature_score_z_mean * -1,\n                                        feature_score_z_mean))\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n#| echo: false\n\npanel_shap_local_0 <- shap_feat_0 |>\n  filter(!is.na(variable_grp)) |> \n  # scale feat score to 0-1\n  mutate(feature_score = (feature_score_z_mean - min(feature_score_z_mean))/(max(feature_score_z_mean)-min(feature_score_z_mean))) |> \n  ggplot(mapping = aes(x = variable_grp, y = value, color = feature_score)) +\n  ggforce::geom_sina(method = \"counts\", maxwidth = .7, alpha = .4) +\n  geom_hline(yintercept = 0) +\n  scale_y_continuous(limits = c(-2, 5), breaks = seq(-2, 5)) +\n  ylab(\"Shapley Value (0 Hour Lag)\") +\n  xlab(NULL) +\n  scale_color_gradientn(colors = c(\"#240e31\", \"#cb6bce\"),\n                        breaks = c(.1, .9),\n                        labels = c(\"low\", \"high\")) +\n  labs(color = NULL) +\n  theme(legend.position = \"right\",\n        legend.key.size = unit(0.25, \"cm\"),\n        axis.text=element_text(size=9.5),\n        panel.border = element_rect(colour = \"black\", fill = NA, linewidth = 1))+\n  coord_flip()\n\npanel_shap_local_24 <- shap_feat_24 |>\n  filter(!is.na(variable_grp)) |> \n  # scale feat score to 0-1\n  mutate(feature_score = (feature_score_z_mean - min(feature_score_z_mean))/(max(feature_score_z_mean)-min(feature_score_z_mean))) |> \n  ggplot(mapping = aes(x = variable_grp, y = value, color = feature_score)) +\n  ggforce::geom_sina(method = \"counts\", maxwidth = .7, alpha = .4) +\n  geom_hline(yintercept = 0) +\n  scale_y_continuous(limits = c(-2, 5), breaks = seq(-2, 5)) +\n  ylab(\"Shapley Value (24 Hour Lag)\") +\n  xlab(NULL) +\n  scale_color_gradientn(colors = c(\"#240e31\", \"#922488\"),\n                        breaks = c(.1, .9),\n                        labels = c(\"low\", \"high\")) +\n  labs(color = NULL) +\n  theme(legend.position = \"right\",\n        legend.key.size = unit(0.25, \"cm\"),\n        axis.text=element_text(size=9.5),\n        panel.border = element_rect(colour = \"black\", fill = NA, linewidth = 1))+\n  coord_flip()\n\npanel_shap_local_72 <- shap_feat_72 |>\n  filter(!is.na(variable_grp)) |> \n  # scale feat score to 0-1\n  mutate(feature_score = (feature_score_z_mean - min(feature_score_z_mean))/(max(feature_score_z_mean)-min(feature_score_z_mean))) |> \n  ggplot(mapping = aes(x = variable_grp, y = value, color = feature_score)) +\n  ggforce::geom_sina(method = \"counts\", maxwidth = .7, alpha = .4) +\n  geom_hline(yintercept = 0) +\n  scale_y_continuous(limits = c(-2, 5), breaks = seq(-2, 5)) +\n  ylab(\"Shapley Value (72 Hour Lag)\") +\n  xlab(NULL) +\n  scale_color_gradientn(colors = c(\"#240e31\", \"#458892\"),\n                        breaks = c(.1, .9),\n                        labels = c(\"low\", \"high\")) +\n  labs(color = NULL) +\n  theme(legend.position = \"right\",\n        legend.key.size = unit(0.25, \"cm\"),\n        axis.text=element_text(size=9.5),\n        panel.border = element_rect(colour = \"black\", fill = NA, linewidth = 1))+\n  coord_flip()\n\npanel_shap_local_168 <- shap_feat_168 |>\n  filter(!is.na(variable_grp)) |> \n  # scale feat score to 0-1\n  mutate(feature_score = (feature_score_z_mean - min(feature_score_z_mean))/(max(feature_score_z_mean)-min(feature_score_z_mean))) |> \n  ggplot(mapping = aes(x = variable_grp, y = value, color = feature_score)) +\n  ggforce::geom_sina(method = \"counts\", maxwidth = .7, alpha = .4) +\n  geom_hline(yintercept = 0) +\n  scale_y_continuous(limits = c(-2, 5), breaks = seq(-2, 5)) +\n  ylab(\"Shapley Value (168 Hour Lag)\") +\n  xlab(NULL) +\n  scale_color_gradientn(colors = c(\"#240e31\", \"#75f3d3\"),\n                        breaks = c(.1, .9),\n                        labels = c(\"low\", \"high\")) +\n  labs(color = NULL) +\n  theme(legend.position = \"right\",\n        legend.key.size = unit(0.25, \"cm\"),\n        axis.text=element_text(size=9.5),\n        panel.border = element_rect(colour = \"black\", fill = NA, linewidth = 1))+\n  coord_flip()\n\n\npanel_shap_local_336 <- shap_feat_336 |>\n  filter(!is.na(variable_grp)) |> \n  # scale feat score to 0-1\n  mutate(feature_score = (feature_score_z_mean - min(feature_score_z_mean))/(max(feature_score_z_mean)-min(feature_score_z_mean))) |> \n  ggplot(mapping = aes(x = variable_grp, y = value, color = feature_score)) +\n  ggforce::geom_sina(method = \"counts\", maxwidth = .7, alpha = .4) +\n  geom_hline(yintercept = 0) +\n  scale_y_continuous(limits = c(-2, 5), breaks = seq(-2, 5)) +\n  ylab(\"Shapley Value (336 Hour Lag)\") +\n  xlab(NULL) +\n  scale_color_gradientn(colors = c(\"#240e31\", \"#f9e79f\"),\n                        breaks = c(.1, .9),\n                        labels = c(\"low\", \"high\")) +\n  labs(color = NULL) +\n  theme(legend.position = \"right\",\n        legend.key.size = unit(0.25, \"cm\"),\n        axis.text=element_text(size=9.5),\n        panel.border = element_rect(colour = \"black\", fill = NA, linewidth = 1))+\n  coord_flip()\n```\n:::\n\n::: {#cell-fig-shap-local .cell}\n\n```{.r .cell-code .hidden}\n#| label: fig-shap-local\n#| fig-cap: \"Local feature importance plots by model.\"\n#| fig-height: 8\n#| fig-width: 10\n\ncowplot::plot_grid(panel_shap_local_0,\n                   panel_shap_local_24,\n                   panel_shap_local_72, \n                   panel_shap_local_168,\n                   panel_shap_local_336, \n                   ncol = 2, labels = c(\"A\", \"B\", \"C\", \"D\", \"E\"), \n                   align = \"hv\")\n```\n\n::: {.cell-output-display}\n![Local feature importance plots by model.](supplement_files/figure-html/fig-shap-local-1.png){#fig-shap-local width=960}\n:::\n:::\n\n\n\n### Figure S4: Individual Shapley Plots for Top Features\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n#| echo: false\n\nshap_feat_all <- shap_feat_0 |> \n  mutate(model = \"0 hours\") |> \n  rbind(shap_feat_24 |> \n  mutate(model = \"24 hours\")) |> \n  rbind(shap_feat_72 |> \n  mutate(model = \"72 hours\")) |> \n  rbind(shap_feat_168 |> \n  mutate(model = \"168 hours\")) |> \n  rbind(shap_feat_336 |> \n  mutate(model = \"336 hours\")) |> \n  mutate(model = factor(model, levels = c(\"0 hours\", \"24 hours\", \"72 hours\",\n                                          \"168 hours\", \"336 hours\")))\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n#| echo: false\n\ncolor_codes <- c(\"#cb6bce\", \"#751c6d\", \"#458892\", \"#75f3d3\", \"#240e31\")\n\nshap_feat_all |> \n  filter(variable_grp == \"past use \") |> \n  ggplot(aes(x = feature_score_z_mean, y = value, color = model)) +\n  geom_point(alpha = .4) +\n  geom_smooth(formula = y ~ x, \n              method = \"loess\", color = \"black\", linewidth = .75) +\n  facet_wrap(~model) +\n  scale_color_manual(values = color_codes) +\n  labs(title = \"Past Use\", y = \"Shapley\", x = \"Feature value\") +\n  theme(legend.position = \"none\",\n        panel.border = element_rect(colour = \"black\", fill = NA, linewidth = 1))\n```\n\n::: {.cell-output-display}\n![](supplement_files/figure-html/unnamed-chunk-11-1.png){width=672}\n:::\n\n```{.r .cell-code .hidden}\n#| echo: false\n\nshap_feat_all |> \n  filter(variable_grp == \"future efficacy \") |> \n  ggplot(aes(x = feature_score_z_mean, y = value, color = model)) +\n  geom_point(alpha = .4) +\n  geom_smooth(formula = y ~ x, \n              method = \"loess\", color = \"black\", linewidth = .75) +\n  facet_wrap(~model) +\n  scale_color_manual(values = color_codes) +\n  labs(title = \"Future Efficacy\", y = \"Shapley\", x = \"Feature value\") +\n  theme(legend.position = \"none\",\n        panel.border = element_rect(colour = \"black\", fill = NA, linewidth = 1))\n```\n\n::: {.cell-output-display}\n![](supplement_files/figure-html/unnamed-chunk-11-2.png){width=672}\n:::\n\n```{.r .cell-code .hidden}\n#| echo: false\n\nshap_feat_all |> \n  filter(variable_grp == \"income \") |> \n  ggplot(aes(x = feature_score_z_mean, y = value, color = model)) +\n  geom_point(alpha = .4) +\n  geom_smooth(formula = y ~ x, \n              method = \"loess\", color = \"black\", linewidth = .75) +\n  facet_wrap(~model) +\n  scale_color_manual(values = color_codes) +\n  labs(title = \"Income\", y = \"Shapley\", x = \"Feature value\") +\n  theme(legend.position = \"none\",\n        panel.border = element_rect(colour = \"black\", fill = NA, linewidth = 1))\n```\n\n::: {.cell-output-display}\n![](supplement_files/figure-html/unnamed-chunk-11-3.png){width=672}\n:::\n\n```{.r .cell-code .hidden}\n#| echo: false\n\nshap_feat_all |> \n  filter(variable_grp == \"craving \") |> \n  ggplot(aes(x = feature_score_z_mean, y = value, color = model)) +\n  geom_point(alpha = .4) +\n  geom_smooth(formula = y ~ x, \n              method = \"loess\", color = \"black\", linewidth = .75) +\n  facet_wrap(~model) +\n  scale_color_manual(values = color_codes) +\n  labs(title = \"Craving\", y = \"Shapley\", x = \"Feature value\") +\n  theme(legend.position = \"none\",\n        panel.border = element_rect(colour = \"black\", fill = NA, linewidth = 1))\n```\n\n::: {.cell-output-display}\n![](supplement_files/figure-html/unnamed-chunk-11-4.png){width=672}\n:::\n\n```{.r .cell-code .hidden}\n#| echo: false\n\nshap_feat_all |> \n  filter(variable_grp == \"future risky situation \") |> \n  ggplot(aes(x = feature_score_z_mean, y = value, color = model)) +\n  geom_point(alpha = .4) +\n  geom_smooth(formula = y ~ x, \n              method = \"loess\", color = \"black\", linewidth = .75) +\n  facet_wrap(~model) +\n  scale_color_manual(values = color_codes) +\n  labs(title = \"Future Risky Situation\", y = \"Shapley\", x = \"Feature value\") +\n  theme(legend.position = \"none\",\n        panel.border = element_rect(colour = \"black\", fill = NA, linewidth = 1))\n```\n\n::: {.cell-output-display}\n![](supplement_files/figure-html/unnamed-chunk-11-5.png){width=672}\n:::\n:::\n\n\n\n\n## Supplemental Tables\n\n### Table S1: Model performance by Demographic Group\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n#| echo: false\n\npp_dem <- pp_dem |> \n  mutate(lag = factor(lag, levels = c(0, 24, 72, 168, 336), \n                        labels = c(\"0 hours\", \"24 hours\", \"72 hours\", \"168 hours\", \"336 hours\" )),\n         model = factor(model, levels = c(\"not white\", \"non-hispanic white\",\n                                        \"female\", \"male\",\n                                        \"below poverty\", \"above poverty\"))) |> \n  arrange(model, lag)\n\npp_dem_all <- pp_dem |> \n  filter(lag == \"0 hours\") |> \n  mutate(pp_lower = round(pp_lower, 3),\n         pp_upper = round(pp_upper, 3),\n         ci = str_c(pp_lower,\"-\",pp_upper)) |>\n  select(-c(lag, pp_lower, pp_upper)) |> \n  bind_cols(pp_dem |> \n  filter(lag == \"24 hours\") |> \n  mutate(pp_lower = round(pp_lower, 3),\n         pp_upper = round(pp_upper, 3),\n         ci = str_c(pp_lower,\"-\",pp_upper)) |>\n  select(-c(lag, pp_lower, pp_upper, model))) |> \n  bind_cols(pp_dem |> \n  filter(lag == \"72 hours\") |> \n  mutate(pp_lower = round(pp_lower, 3),\n         pp_upper = round(pp_upper, 3),\n         ci = str_c(pp_lower,\"-\",pp_upper)) |>\n  select(-c(lag, pp_lower, pp_upper, model))) |> \n  bind_cols(pp_dem |> \n  filter(lag == \"168 hours\") |> \n  mutate(pp_lower = round(pp_lower, 3),\n         pp_upper = round(pp_upper, 3),\n         ci = str_c(pp_lower,\"-\",pp_upper)) |>\n  select(-c(lag, pp_lower, pp_upper, model))) |> \n  bind_cols(pp_dem |> \n  filter(lag == \"336 hours\") |> \n  mutate(pp_lower = round(pp_lower, 3),\n         pp_upper = round(pp_upper, 3),\n         ci = str_c(pp_lower,\"-\",pp_upper)) |>\n  select(-c(lag, pp_lower, pp_upper, model))) |> \n  add_row(model = \"Race/Ethnicity\", .before = 1) |> \n  add_row(model = \"Sex at Birth\", .before = 4) |> \n  add_row(model = \"Income\", .before = 7) |> \n  suppressMessages()\n```\n:::\n\n::: {#tbl-fairness .cell tbl-cap='Model Performance by Demographic Group'}\n\n```{.r .cell-code .hidden}\n#| label: tbl-fairness\n#| tbl-cap: \"Model Performance by Demographic Group\"\n\npp_sex <- pp_dem_contrast |> \n  filter(contrast == \"female vs male\") |> \n   mutate(ci = str_c(\"[\", round(lower, 3), \", \", round(upper, 3), \"]\"),\n         median = as.character(round(median, 3)),\n         probability = as.character(round(probability, 3))) |> \n  select(lag, median, ci, probability) |> \n  rename(`Lag (hours)`= lag,\n         Median = median,\n         `Bayesian CI` = ci,\n         Probability = probability)\n\npp_income <- pp_dem_contrast |> \n  filter(contrast == \"below poverty vs above poverty\") |> \n   mutate(ci = str_c(\"[\", round(lower, 3), \", \", round(upper, 3), \"]\"),\n         median = as.character(round(median, 3)),\n         probability = as.character(round(probability, 3))) |> \n  select(lag, median, ci, probability) |> \n  rename(`Lag (hours)`= lag,\n         Median = median,\n         `Bayesian CI` = ci,\n         Probability = probability)\n\npp_race <- pp_dem_contrast |> \n  filter(contrast == \"not white vs non-hispanic white\") |> \n   mutate(ci = str_c(\"[\", round(lower, 3), \", \", round(upper, 3), \"]\"),\n         median = as.character(round(median, 3)),\n         probability = as.character(round(probability, 3))) |> \n  select(lag, median, ci, probability) |> \n  rename(`Lag (hours)`= lag,\n         Median = median,\n         `Bayesian CI` = ci,\n         Probability = probability)\n```\n:::\n\n\nSex\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\npp_sex\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 5 × 4\n  `Lag (hours)` Median `Bayesian CI`    Probability\n          <dbl> <chr>  <chr>            <chr>      \n1             0 -0.058 [-0.075, -0.043] 0          \n2            24 -0.071 [-0.089, -0.054] 0          \n3            72 -0.08  [-0.099, -0.063] 0          \n4           168 -0.096 [-0.116, -0.076] 0          \n5           336 -0.116 [-0.141, -0.094] 0          \n```\n\n\n:::\n:::\n\n\nIncome\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\npp_income\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 5 × 4\n  `Lag (hours)` Median `Bayesian CI`    Probability\n          <dbl> <chr>  <chr>            <chr>      \n1             0 -0.091 [-0.137, -0.049] 0          \n2            24 -0.087 [-0.127, -0.05]  0          \n3            72 -0.092 [-0.135, -0.054] 0          \n4           168 -0.133 [-0.175, -0.092] 0          \n5           336 -0.132 [-0.173, -0.091] 0          \n```\n\n\n:::\n:::\n\n\nRace\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\npp_race\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 5 × 4\n  `Lag (hours)` Median `Bayesian CI`    Probability\n          <dbl> <chr>  <chr>            <chr>      \n1             0 -0.166 [-0.262, -0.088] 0          \n2            24 -0.175 [-0.287, -0.085] 0.002      \n3            72 -0.161 [-0.231, -0.097] 0          \n4           168 -0.147 [-0.202, -0.098] 0          \n5           336 -0.108 [-0.158, -0.064] 0          \n```\n\n\n:::\n:::\n",
    "supporting": [
      "supplement_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}